{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages, constants, and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directories in c:\\Users\\tobia\\Vs code\\02807\\proj\\02807_project_Group13\\\n",
      " ['.git', 'classes.py', 'constants.py', 'functions.py', 'joblib_vars', 'Notebook.ipynb', 'raw_data', 'README.md', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import functions as f\n",
    "import constants as c\n",
    "import classes as cl\n",
    "\n",
    "import pandas as pd\n",
    "import os, joblib, time\n",
    "print(f\"Current directories in {c.cwd}\\n {os.listdir()}\")\n",
    "\n",
    "long = c.cwd + \"\\\\raw_data\\\\long_alzheimers.tsv\"\n",
    "short = c.cwd + \"\\\\raw_data\\\\short_alzheimers.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating id_prot and saving\n",
    "id_prot is a dictionary meant to point a id <integer> to a protein name <string> with 19 str characters \\\n",
    "id_prot is saved using joblib.dump() in dir \"joblib_vars\", and can be reloaded as a dict object using joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "info_df = pd.read_csv(\"https://stringdb-downloads.org/download/protein.info.v12.0/9606.protein.info.v12.0.txt.gz\", compression='gzip', sep=\"\\t\")\n",
    "info_df = info_df[[\"#string_protein_id\"]].values\n",
    "id_prot = dict()\n",
    "for c, e in enumerate(info_df):\n",
    "    id_prot[c] = e[0]\n",
    "print(id_prot)\n",
    "joblib.dump(id_prot, \"./joblib_vars/id_prot.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying raw datasets\n",
    "modified datasets are stored in \"/mod_data/\" for easy retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An example of an interaction dataset loaded\n",
    "\"\"\"\n",
    "alz_int_df = pd.read_csv(\"./raw_data/long_alzheimers.tsv\", sep=\"\\t\")\n",
    "alz_int_df.columns = [\"Prot1_ShortName\", \"Prot2_ShortName\", \"protein1\", \"protein2\", \"col1\", \"col2\", \"col3\", \"col4\", \"col5\", \"col6\", \"col7\", \"col8\", \"col9\"]\n",
    "alz_int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HS_int_df = pd.read_csv(\"https://stringdb-downloads.org/download/protein.links.detailed.v12.0/9606.protein.links.detailed.v12.0.txt.gz\", compression=\"gzip\", sep=\" \")\n",
    "HS_int_df = HS_int_df[HS_int_df[\"experimental\"] > 0] #removing interactions with no experimental relevance \n",
    "#joblib.dump(HS_int_df, \"./joblib_vars/HS_int_df\") #FILE TOO LARGE \n",
    "HS_int_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating HS_int_simple, containing protein1 and protein2 names converted to int using id_prot. \\\n",
    "If all interactions are weight=1, only the names (ids) of the proteins are needed when constructing the interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_prot = joblib.load(\"./joblib_vars/id_prot.joblib\")\n",
    "\n",
    "#Swapping key value in dict\n",
    "id_swap = dict()\n",
    "for k, v in id_prot.items():\n",
    "    id_swap[str(v)] = k\n",
    "print(id_swap)\n",
    "\n",
    "#exporting modified HS_int\n",
    "HS_int_simple = HS_int_df.map(lambda x: id_swap[x] if x in id_swap else x).reset_index()\n",
    "HS_int_simple = HS_int_simple[[\"protein1\", \"protein2\"]]\n",
    "joblib.dump(HS_int_simple, \"./joblib_vars/HS_int_simple.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes & Edges creation from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for a in HS_int_simple.iterrows():\n",
    "    print(a[1][\"protein1\"], a[1][\"protein2\"])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD / OUTDATED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Interaction dataset loaded for homo sapiens (HS) related data\n",
    "Saving data with int. ids from id_prot\n",
    "Raw Data has the headings: [protein1\tprotein2\tneighborhood\tfusion\tcooccurence\tcoexpression\texperimental\tdatabase\ttextmining\tcombined_score]\n",
    "\n",
    "Runtime\n",
    "Number of rows in HS protein links dataset: 13715404\n",
    "Chunksize; reading one line per value \n",
    "Runtime when chunksize=200000; \n",
    "\"\"\"\n",
    "chunksize = 200000\n",
    "LinesRead = 0 \n",
    "HS_int_df = pd.DataFrame() #df for storing\n",
    "id_prot = joblib.load(\"./joblib_vars/id_prot.joblib\")\n",
    "logfile = open(\"./logs/IntRawData_logs.txt\", \"w\")\n",
    "\n",
    "for chunk in pd.read_csv(\"https://stringdb-downloads.org/download/protein.links.detailed.v12.0/9606.protein.links.detailed.v12.0.txt.gz\", compression=\"gzip\", chunksize=chunksize, sep=\" \"):\n",
    "    print(f\"Time: {time.ctime(time.time())}\\tReading lines {LinesRead} - {LinesRead+chunksize}...\", file=logfile)\n",
    "    print(f\"Time: {time.ctime(time.time())}\\tReading lines {LinesRead} - {LinesRead+chunksize}...\")\n",
    "    chunk[\"protein1\"] = chunk[\"protein1\"].map(id_prot) #Changing names to id's using id_prot\n",
    "    chunk[\"protein2\"] = chunk[\"protein2\"].map(id_prot) #Changing names to id's using id_prot\n",
    "    HS_int_df = pd.concat([HS_int_df, chunk], axis=1)\n",
    "    LinesRead += chunksize\n",
    "    print(f\"Time: {time.ctime(time.time())}\\tLines read {LinesRead}/13,715,404\", file=logfile)\n",
    "    print(f\"Time: {time.ctime(time.time())}\\tLines read {LinesRead}/13,715,404\")\n",
    "\n",
    "joblib.dump(HS_int_df,\"./mod_data/HS_int_df.joblib\")\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the color of the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating encoding table\n",
      "Fetching data\n",
      "Cropping data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6977741a1847658fb34be0a63a0964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing data:   0%|          | 0/5847852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = cl.interaction_network()\n",
    "a.create_encoding_dict()\n",
    "a.load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
