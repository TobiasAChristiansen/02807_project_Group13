{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages, constants, and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as f\n",
    "import constants as c\n",
    "import classes as cl\n",
    "\n",
    "import pandas as pd\n",
    "import os, joblib, time\n",
    "\n",
    "from netwulf import visualize\n",
    "print(f\"Current directories in {c.cwd}\\n {os.listdir()}\")\n",
    "\n",
    "long = c.cwd + \"\\\\raw_data\\\\long_alzheimers.tsv\"\n",
    "short = c.cwd + \"\\\\raw_data\\\\short_alzheimers.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating id_prot and saving\n",
    "id_prot is a dictionary meant to point a id <integer> to a protein name <string> with 19 str characters \\\n",
    "id_prot is saved using joblib.dump() in dir \"joblib_vars\", and can be reloaded as a dict object using joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "info_df = pd.read_csv(\"https://stringdb-downloads.org/download/protein.info.v12.0/9606.protein.info.v12.0.txt.gz\", compression='gzip', sep=\"\\t\")\n",
    "info_df = info_df[[\"#string_protein_id\"]].values\n",
    "id_prot = dict()\n",
    "for c, e in enumerate(info_df):\n",
    "    id_prot[c] = e[0]\n",
    "print(id_prot)\n",
    "joblib.dump(id_prot, \"./joblib_vars/id_prot.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying raw datasets\n",
    "modified datasets are stored in \"/mod_data/\" for easy retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An example of an interaction dataset loaded\n",
    "\"\"\"\n",
    "alz_int_df = pd.read_csv(\"./raw_data/long_alzheimers.tsv\", sep=\"\\t\")\n",
    "alz_int_df.columns = [\"Prot1_ShortName\", \"Prot2_ShortName\", \"protein1\", \"protein2\", \"col1\", \"col2\", \"col3\", \"col4\", \"col5\", \"col6\", \"col7\", \"col8\", \"col9\"]\n",
    "alz_int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HS_int_df = pd.read_csv(\"https://stringdb-downloads.org/download/protein.links.detailed.v12.0/9606.protein.links.detailed.v12.0.txt.gz\", compression=\"gzip\", sep=\" \")\n",
    "HS_int_df = HS_int_df[HS_int_df[\"experimental\"] > 0] #removing interactions with no experimental relevance \n",
    "#joblib.dump(HS_int_df, \"./joblib_vars/HS_int_df\") #FILE TOO LARGE \n",
    "HS_int_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating HS_int_simple, containing protein1 and protein2 names converted to int using id_prot. \\\n",
    "If all interactions are weight=1, only the names (ids) of the proteins are needed when constructing the interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_prot = joblib.load(\"./joblib_vars/id_prot.joblib\")\n",
    "\n",
    "#Swapping key value in dict\n",
    "id_swap = dict()\n",
    "for k, v in id_prot.items():\n",
    "    id_swap[str(v)] = k\n",
    "print(id_swap)\n",
    "\n",
    "#exporting modified HS_int\n",
    "HS_int_simple = HS_int_df.map(lambda x: id_swap[x] if x in id_swap else x).reset_index()\n",
    "HS_int_simple = HS_int_simple[[\"protein1\", \"protein2\"]]\n",
    "joblib.dump(HS_int_simple, \"./joblib_vars/HS_int_simple.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the color of the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cl.interaction_network(testdataset = True, threshold=0.05)\n",
    "a.create_encoding_dict()\n",
    "a.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code for the format of a.vertices\n",
    "for root in a.vertices.keys():\n",
    "    print(\"root\", \"neighbor\", \"norm_score\")\n",
    "    for neighbor in a.vertices[root].keys():\n",
    "        print(root, neighbor, a.vertices[root][neighbor])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.construct_graph(a.vertices)\n",
    "#visualize(a.graph_network) #DANGER: large visualization - Returns html graph, aka. opens up visualization in browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of shortest_path\n",
    "vertexes = {\"A\": {\"B\": 0.1, \"C\": 0.2},\n",
    "            \"B\": {\"A\": 0.1, \"C\": 0.1, \"D\": 0.4},\n",
    "            \"C\": {\"A\": 0.2, \"B\": 0.1},\n",
    "            \"D\": {\"B\": 0.4, \"E\": 0.2},\n",
    "            \"E\": {\"D\": 0.2}}\n",
    "\n",
    "# Make sure you reference the correct function name\n",
    "#for start_end in (paths := f.shortest_path(\"A\", vertexes)):\n",
    "#    print(start_end, paths[start_end], sep = \":   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_used = a.evaluate_most_used_path(a.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_used = sorted(edges_used.items(), key = lambda x:x[1], reverse=True)\n",
    "for i in range(10):\n",
    "    print(edges_used[i][0], edges_used[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.vertices.keys())\n",
    "print(len(a.vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of check_connection\n",
    "vertexes = {\"A\": [\"B\", \"C\"],\n",
    "            \"B\": [\"A\", \"C\", \"D\"],\n",
    "            \"C\": [\"A\", \"B\"],\n",
    "            \"D\": [\"B\", \"E\"],\n",
    "            \"E\": [\"D\"],\n",
    "            \"F\": [\"G\"],\n",
    "            \"G\": [\"F\"]}\n",
    "\n",
    "is_connected, connected_vertices = check_connection(vertexes)\n",
    "print(\"The network is fully connected: {}\".format(is_connected))\n",
    "for i, group in enumerate(connected_vertices):\n",
    "    print(\"Grouped vertices {}:\".format(i+1))\n",
    "    print(group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
