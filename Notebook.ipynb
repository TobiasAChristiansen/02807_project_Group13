{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages, constants, and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\tobia\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directories in c:\\Users\\tobia\\Vs code\\02807\\proj\\02807_project_Group13\\\n",
      " ['.git', '.gitignore', 'classes.py', 'constants.py', 'enrichment.ipynb', 'functions.py', 'joblib_vars', 'modularity.ipynb', 'Notebook.ipynb', 'OldCode_saveforReport.ipynb', 'raw_data', 'README.md', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import functions as f\n",
    "import constants as c\n",
    "import classes as cl\n",
    "\n",
    "import pandas as pd\n",
    "import os, joblib, time\n",
    "\n",
    "from netwulf import visualize\n",
    "print(f\"Current directories in {c.cwd}\\n {os.listdir()}\")\n",
    "\n",
    "long = c.cwd + \"\\\\raw_data\\\\long_alzheimers.tsv\"\n",
    "short = c.cwd + \"\\\\raw_data\\\\short_alzheimers.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating id_prot and saving\n",
    "id_prot is a dictionary meant to point a id <integer> to a protein name <string> with 19 str characters \\\n",
    "id_prot is saved using joblib.dump() in dir \"joblib_vars\", and can be reloaded as a dict object using joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10\n",
    "info_df = pd.read_csv(\"https://stringdb-downloads.org/download/protein.info.v12.0/9606.protein.info.v12.0.txt.gz\", compression='gzip', sep=\"\\t\")\n",
    "info_df = info_df[[\"#string_protein_id\"]].values\n",
    "id_prot = dict()\n",
    "for c, e in enumerate(info_df):\n",
    "    id_prot[c] = e[0]\n",
    "print(id_prot)\n",
    "joblib.dump(id_prot, \"./joblib_vars/id_prot.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying raw datasets\n",
    "modified datasets are stored in \"/mod_data/\" for easy retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An example of an interaction dataset loaded\n",
    "\"\"\"\n",
    "alz_int_df = pd.read_csv(\"./raw_data/long_alzheimers.tsv\", sep=\"\\t\")\n",
    "alz_int_df.columns = [\"Prot1_ShortName\", \"Prot2_ShortName\", \"protein1\", \"protein2\", \"col1\", \"col2\", \"col3\", \"col4\", \"col5\", \"col6\", \"col7\", \"col8\", \"col9\"]\n",
    "alz_int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HS_int_df = pd.read_csv(\"https://stringdb-downloads.org/download/protein.links.detailed.v12.0/9606.protein.links.detailed.v12.0.txt.gz\", compression=\"gzip\", sep=\" \")\n",
    "HS_int_df = HS_int_df[HS_int_df[\"experimental\"] > 0] #removing interactions with no experimental relevance \n",
    "#joblib.dump(HS_int_df, \"./joblib_vars/HS_int_df\") #FILE TOO LARGE \n",
    "HS_int_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating HS_int_simple, containing protein1 and protein2 names converted to int using id_prot. \\\n",
    "If all interactions are weight=1, only the names (ids) of the proteins are needed when constructing the interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m id_prot \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./joblib_vars/id_prot.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Swapping key value in dict\u001b[39;00m\n\u001b[0;32m      4\u001b[0m id_swap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "id_prot = joblib.load(\"./joblib_vars/id_prot.joblib\")\n",
    "\n",
    "#Swapping key value in dict\n",
    "id_swap = dict()\n",
    "for k, v in id_prot.items():\n",
    "    id_swap[str(v)] = k\n",
    "print(id_swap)\n",
    "\n",
    "#exporting modified HS_int\n",
    "HS_int_simple = HS_int_df.map(lambda x: id_swap[x] if x in id_swap else x).reset_index()\n",
    "HS_int_simple = HS_int_simple[[\"protein1\", \"protein2\"]]\n",
    "joblib.dump(HS_int_simple, \"./joblib_vars/HS_int_simple.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the color of the progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating encoding table\n",
      "Fetching data\n",
      "Cropping data\n",
      "Given threshold: 0.95 filtered out combined_score values: 891.0 and below\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832a1c52bbf14a38be2aa9c32235bb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing data:   0%|          | 0/11260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in var .vertices, with size: 0.03696mb\n"
     ]
    }
   ],
   "source": [
    "a = cl.interaction_network(testdataset = True, threshold=0.05)\n",
    "a.create_encoding_dict()\n",
    "a.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code for the format of a.vertices\n",
    "for root in a.vertices.keys():\n",
    "    print(\"root\", \"neighbor\", \"norm_score\")\n",
    "    for neighbor in a.vertices[root].keys():\n",
    "        print(root, neighbor, a.vertices[root][neighbor])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.construct_graph(a.vertices)\n",
    "#visualize(a.graph_network) #DANGER: large visualization - Returns html graph, aka. opens up visualization in browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of shortest_path\n",
    "vertexes = {\"A\": {\"B\": 0.1, \"C\": 0.2},\n",
    "            \"B\": {\"A\": 0.1, \"C\": 0.1, \"D\": 0.4},\n",
    "            \"C\": {\"A\": 0.2, \"B\": 0.1},\n",
    "            \"D\": {\"B\": 0.4, \"E\": 0.2},\n",
    "            \"E\": {\"D\": 0.2}}\n",
    "\n",
    "# Make sure you reference the correct function name\n",
    "#for start_end in (paths := f.shortest_path(\"A\", vertexes)):\n",
    "#    print(start_end, paths[start_end], sep = \":   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_used = a.evaluate_most_used_path(a.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2070-4692 629096\n",
      "3871-4577 599698\n",
      "1723-2483 485137\n",
      "2073-2377 421783\n",
      "3235-846 391761\n",
      "2070-5284 355047\n",
      "2070-2656 337233\n",
      "3056-3631 334348\n",
      "1720-3056 326682\n",
      "4589-846 303695\n"
     ]
    }
   ],
   "source": [
    "edges_used = sorted(edges_used.items(), key = lambda x:x[1], reverse=True)\n",
    "for i in range(10):\n",
    "    print(edges_used[i][0], edges_used[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.vertices.keys())\n",
    "print(len(a.vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of check_connection\n",
    "vertexes = {\"A\": [\"B\", \"C\"],\n",
    "            \"B\": [\"A\", \"C\", \"D\"],\n",
    "            \"C\": [\"A\", \"B\"],\n",
    "            \"D\": [\"B\", \"E\"],\n",
    "            \"E\": [\"D\"],\n",
    "            \"F\": [\"G\"],\n",
    "            \"G\": [\"F\"]}\n",
    "\n",
    "is_connected, connected_vertices = check_connection(vertexes)\n",
    "print(\"The network is fully connected: {}\".format(is_connected))\n",
    "for i, group in enumerate(connected_vertices):\n",
    "    print(\"Grouped vertices {}:\".format(i+1))\n",
    "    print(group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
